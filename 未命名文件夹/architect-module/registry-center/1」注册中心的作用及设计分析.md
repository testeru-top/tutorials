# 1」注册中心的作用及设计分析
## 注册中心概念
- 用来实现微服务实例的自动注册与发现
- 是分布式系统中的核心基础服务

### 没有注册中心的时候 
#### 模块各自维护 


![](https://gitee.com/datau001/picgo/raw/master/images/202112232206655.png)

- `ServiceC`对应是一个集群，有4个节点组成
- `Service1`本地有一个配置文件，配置
```
ServiceC-1=192.168.1.1:58100
ServiceC-2=192.168.1.2:58100
ServiceC-3=192.168.1.3:58100
...
```
- 有运营活动的时候，上游` Service1` 去通知下游` ServiceC `进行扩容，扩容出来`C-4`、` C-5` 2个节点
- 但是对应`ServiceC`而言，谁调用我，我是不知道的
- 配置文件配置在服务上游模块，指明了下游的服务列表

#### 全局配置文件

- `global.conf`
- 一般运维同学维护，对应`ServiceC`能一目了然的看到上游是谁调用我
> 配置文件虽然知道对应的上游服务是谁，但是上游服务相关研发负责人并不能及时响应，对应时间成本增加

```
其他服务回应：我这会忙项目开发，对应的迭代很快，服务无法及时重启，等我下次上线再帮你重启得了
```


## 总结
- 能用技术的手段解决 管理的问题，那就是节约成本，为整个组织带来很大的效益
- 注册中心能解决跨部门协作的问题

> 服务实例的自动注册与发现，是分布式系统中的核心    

## 注册中心4大核心功能 
- RPC有8大块，注册中心有4大块
### 服务注册 
### 服务发现 
### 健康检查 
### 变更通知

![](https://gitee.com/datau001/picgo/raw/master/images/202112232228611.png)

# 注册中心业务模型
![](https://gitee.com/datau001/picgo/raw/master/images/202112232246350.png)

- 1.**提供方**主动发起了 **服务注册** 给注册中心
- 2.**消费方**主动发起了 **服务发现** 给注册中心

> 以上2个步骤对应`发起方不是 注册中心`
>
> 目前为止，解决了配置文件的问题

- 3.注册中心主动发起 健康检查 给提供方
- 4.对应提供方和消费方，消费方通过RPC调用提供方
- 5.提供方有多个服务，当其中一个服务下掉的时候，注册中心需要通过健康检查得到结果「3步」
- 6.注册中心接收到服务下架通知后，对应通过 变更通知 告诉消费方
  - 健康检查、变更通知 都是**注册中心发起的动作**

## 注册中心组成

### 服务注册 
- **服务提供方**将自身**路由信息**发布到**注册中心**，供**服务消费方获取**，然后用于与提供方建立连接和发起调用

> 以下内容发布到注册中心
### 1.路由信息 
- 注册服务节点IP、监听端口等路由信息 
  - 把 IP、port 相关信息发送给注册中心
  - 不写对应服务节点IP，(建议)写对应域名，当一个服务器坏了，IP直接没了；但是域名涉及到对应的DNS，运维会重新找一台新的机器，把对应IP和域名进行DNS映射
### 2.服务信息 

> 扩展类注册信息

##### 序列化协议 
- json、xml、db序列化
##### 路由规则 

- 灰度对应的路由规则组成

##### 节点权重 


- 服务治理相关知识
![](https://gitee.com/datau001/picgo/raw/master/images/202112242121200.png)

## 服务发现

**服务消费方**通过和**注册中心**交互获取**服务提供方节点的路由信息**


- 通过怎样的一种交互方式去发现

    - 消费方通过怎样**可靠的**连接到注册中心，去拿到提供方的相关信息
      - **消费方**从开始启动就可以`实时`的、`可靠`的从**注册中心**拿到**提供方**的**路由**信息

### 1 启动拉取 
服务**消费方**`启动`后，从注册中心拉取提供方节点列表，建立连接，进行`RPC`调用
- 只要启动了就立刻去拉取
- 方便消费方向提供方发起`RPC`调用


### 2 通知回调 
> 订阅 ：注册中心有一个，但是消费方有多(m)个， 注册中心不是每次都推消息给消费方，只有是变化的时候才会把消息推送给消费方


接受注册中心变更通知，重新获取数据，更新节点列表 

> 存在一定的不可靠性：注册方对应节点变化很快「1、2、3」，注册中心不能顺序「1、2、3」通知给消费方----{通知事件带来的歧义问题}
##### 通知回调的方式

![](https://gitee.com/datau001/picgo/raw/master/images/202112251045705.png)

### 3 轮询拉取 
> 兜底策略

服务消费方运行过程中**定时**`拉取`服务`提供方节点列表`，用来更新本地数据

**以上三步保证了轮询可靠性** 

## 健康检查 
> 注册中心发起


确保已注册节点的健康度，能够及时准确剔除失效节点，保证服务发现正确性。

###  失效原因

#####  部署重启
- 上线的时候经常发生，迭代上线
  - 通过上报心跳来发现
#####  异常终止
- 怎么发现异常终止
  - 通过上报心跳来发现
#####  服务假死 
> 假死：线程池当中的所有的线程全部处于忙碌或者阻塞状态

![](https://gitee.com/datau001/picgo/raw/master/images/202112292153265.png)
- 这个时候虽然整个进程还存在，但是对应的该进程已经不工作了
- 虽然服务假死，但是对应心跳还能上报成功
> 心跳是单独的一个线程，叫心跳线程
### 解决方案 

##### 上报心跳 
- 注册中心通过服务提供方的心跳来发现是否可以正常工作
- 心跳发出的动作，由节点Node的进程来发送的，如果Node宕机，对应该进程都没有怎么发送心跳，则判断服务异常

![](https://gitee.com/datau001/picgo/raw/master/images/202112251534595.png)

##### 服务探测
- 心跳上报到服务中心正常，但是对应的下游服务假死状态，这个时候注册中心通过**服务探测**来确定这种情况 
- 注册中心模拟上游请求发送一个探测包
  - 比如说发送一个/ping 请求，如果对应服务方正常则注册中心会快速接收到请求结果；如果迟迟得不到返回结果，说明服务提供方假死状态
  - 一般2次请求失败判断假死，但是这个也是可以进行配置的

## 变更通知 

当服务提供方节点发生变更时，注册中心能够第一时间把**变更事件**或**变更后的数据**推送到订阅方。 

### 订阅与通知

注册中心内为每个服务提供方建立订阅列表，当服务方节点变更时通知所有订阅该服务的消费方节点


![](https://gitee.com/datau001/picgo/raw/master/images/202112292207872.png)

- `provideB-Sub`：`provideB`的订阅方
- 注册中心  需要把provider的N2节点  挂了 通知到 Consumer2 Consumer3


# 注册中心设计
![](https://gitee.com/datau001/picgo/raw/master/images/202112251825884.png)

问题：
- 注册中心真正实现是一个分布式的集群，只不过图中只是画了一个节点
- 提供方连接的节点和消费方连接的节点不一定是同一个注册中心的节点
- 涉及到注册中心集群内数据同步，变更通知的问题

```
集群维度：  CA   <----->   PA
节点维度：  CA-1 <----->   PA-1

集群维度来进行存储
```



## 问题


### 数据存储  

### 超时处理

### 数据同步

## 数据存储



### 数据组织 

#### 集群维度 

#### 节点维度 

![](https://gitee.com/datau001/picgo/raw/master/images/202112292235687.png)

- 用`kList`结构来进行存储
  - 对应提供方`Provider`的对应关系
  - 消费方`Consumer`同样的对应关系

### 订阅数据组织

- 消费方可以订阅多个提供方
- 提供方也可以订阅多个消费方


- 数据就是多对多存储
- 都是kList结构

![](https://gitee.com/datau001/picgo/raw/master/images/202112292304107.png)

## 超时处理

对应的超时是根据心跳来决定的

- 考察心跳算法的问题：
  - 1.遍历扫描算法 
####  遍历扫描 
![](https://gitee.com/datau001/picgo/raw/master/images/202112252010566.png)

- 假如30s上报一次心跳，那一般是2个心跳的生命周期60s
  - 服务端判断2个心跳生命周期，60s如果还没有心跳上报的情况下，判定 健康度是最低的，客户端死掉了
- 会有一个遍历的线程来循环遍历map
- 遍历c1,c2,...c10000，判断t1时间，有多久没有上报心跳
- 当我在遍历读取心跳的时候，会有新的心跳写入  
- 遍历的线程和心跳写入的线程不是同一个
- 多线程对同一个资源map的读写操作
- 加锁条件：多线程对同一资源  进行读写请求、同时写请求
  - 同时读的请求可以加一个共享锁

> 最基本的一个算法，可以优化，因为每次遍历都需要加锁；这个时候用第2种算法：链表法


![](https://gitee.com/datau001/picgo/raw/master/images/202112252024711.png)
- 尾插法
- 所有的节点按照心跳的时间进行排序
- 这样去遍历的时候只需要遍历链表的前面一小部分节点就可以，不需要把整个都遍历，节省了时间「前面的节点是很久没有收到心跳包的客户端，健康度比较好的，每个30s 就来心跳包的节点肯定在后面，不在前面」
- 所以，每次找到节点对应的心跳是新的，就不需要再找了，代表后面的心跳包都是正常的
- 链表确实占用一部分空间，通过空间换取时间 
#### 动态分组 
- 是第3种算法
- 在RM里面专门实现的算法
- 