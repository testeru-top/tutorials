---
notebook: 架构设计
title: 01.RPC框架剖析与设计
tags: 架构,设计,RPC
---


# 01」RPC实现原理深入分析
- 一个模块根据`消费关系`定义是**消费方**还是**提供方**
## 定义
`RPC`(`Remote Procedure Call`):

- 远程过程调用，`Remote Procedure Call Protocol`它是一个**计算机通信协议**

- 它允许**像调用本地方法一样调用远程服务**

- 由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据



## RPC作用
##### 屏蔽组包解包 
直接声明对象调用
```java
A a = new A();
//a调用get()不是在本地生成的,需要远端实现，本地只是进行一个调用
a.get();
```
##### 屏蔽数据发送/接收 
##### 提高开发效率 
- 减少了联调时间，对应的开发业务没有减少
##### 业务发展的必然产物
- http慢，rpc是长链接的
- 麻烦在组装数据解析数据
- 效率高
## RPC意义
是长链接的,麻烦在自己组装数据,发数据,接收数据;效率高了.


## RPC核心组成
##### 远程方法对象代理 
```java
A a = new A();
//a调用get()不是在本地生成的,需要远端调用,怎么调用不关心,
//但是我本地调用a.get()可以跑起来
a.get();
```
说明在本地有人实现了这个`get()`方法,只不过不是我自己实现的;
- 谁来实现的?
    - 框架实现的.
- 框架实现`get()`方法做了哪些事情?
    - 框架不是真正把功能实现了,做了屏蔽的功能「屏蔽组包解包;屏蔽数据发送接收」
    组的数据包组好了,发送的数据,返回的数据

`get()`远程方法对象的代理类,虽然没有实现这个`get()`方法,但是它帮我把数据获取到了,做了远端调用
##### 连接管理 
`A`到`B`连接,需要维护着,谁维护?`RPC`
- 建立多少条连接
- 我要连接哪一个

##### 序列化/反序列化 
get()方法传输一个对象uid,传输的是一个字节流,不能把uid这个long对象直接传递过去,怎么办??

- 我们做一个:obj转换为byte数组「这个转换就叫序列化」

远端方法收到的数据就是一个字节流的包,解析出来,我要把字节流转换出来称一个long对象「这个转换叫反序列化」

同样从远端返回给A.get()的结果,也是需要序列化和反序列化的

在框架中,这部分工作量也被屏蔽了
##### 寻址与负载均衡
分布式系统中保证高可用

- 一个节点都部署多个,进行冗余部署

- 哪怕有天B节点挂掉，可以把流量往其他两个节点发送

![202111061857375](https://gitee.com/datau001/picgo/raw/master/images/202111162133497.png)

## RPC调用方式
RPC肯定要一来一回的传输数据
##### 同步调用
##### 异步调用
更多的是看我们的业务是否允许我们这样做

![202111071020604](https://gitee.com/datau001/picgo/raw/master/images/202111162142045.png)
- 这个`1,2,3`如果是同步调用,则需要`120ms`
- `2,3`业务参数需要依赖1的返回结果去进行调用,我们可以先调用1,然后异步调用2,3
这样总共的时间是50+40=90ms
- **业务上的同异步**
- 框架上都是非阻塞的异步`IO`;和调的`netty`的同异步不一样


## RPC调用过程
![202111071039388](https://gitee.com/datau001/picgo/raw/master/images/202111162144104.png)
- `Consumer`进行`get()`方法的调用,`Provider`进行`get()`方法的具体业务逻辑编写
- 1. 对应的`Consumer`「调用方」的`get()`方法首先通过创建的**远程代理**进行**数据的序列化(转换为流)**
- 2. 序列化后通过**网络模块**传递给**Provider「服务方」**,`Provider`通过**网络模块进行收数据**,收到的数据是一个**字节流**,把**字节流还原成本地对象**「`反序列化`」
- 3. 服务提供方做一个**代理**去调用`get()`真正实现的方法逻辑,调用完成后**返回一系列的对象**(比如:`获取到user实体`),代理类收到返回结果,开始进行**序列化,转换为字节流**,通过**网络传输**,传输给**调用方**「`Consumer`」
- 4. 调用方收到返回的数据以后,是一个网络包,**网络字节流**,给它做一个**反序列化**,反序列化后就把**user实体还原出来了**,还原出来后代理类返回,`get()`就返回了,`user`实体就拿到了.

#### 远程代理

#### 序列化

#### 网络传输

#### 反序列化

# 02」精简版`RPC`调用代码实现
## 假如没有`RPC`，实现远程调用需要做哪些事
如果没有RPC框架支持，实现远程调用需要做哪些事???


- 1. **`Server` 端工作** , **监听端口** , 启动服务就是建立监听端口,代码打开一个端口进行监听
- 2. **`Client` 端工作** , **建立与`Server`的连接**
- 3. **`Server` 端工作** , 响应客户端的连接请求,  **响应连接请求** ;「长链接建立好了」 建立好连接后,`Client` 端就可以进行网络调用了
- 4. **`Client` 端工作** , **组装数据** , 组装我们调用的数据,进行序列化
- 5. **`Client` 端工作** , **发送数据包** , 组装为字节流,把数据发出去
- 6. **`Server` 端工作** , **接收数据包** , 作为server方我们接收到这个数据
- 7. **`Server` 端工作** , **解析数据包，调用相应方法** , 解析数据包其实就是`把字节流还原成本地对象`(反序列化的事情),通过序列化和反序列化约定了一种解析方式,根据约定方式,就知道你想要调用的方法和传入的参数
- 8. **`Server` 端工作** , **组装请求处理结果数据包** , 调用完方法后,返回结果,我们代理类把结果返回,实际就是在`RPC`里面做结果的封装,序列化组包
- 9. **`Server` 端工作** , **发送结果数据包** ,组完包以后,发送数据到`client`
- 10. **`Client` 端工作** , **接收处理结果数据包** , **解析返回数据包** , 接收`server`的结果数据包,进行反序列化解析

![202111071413749](https://gitee.com/datau001/picgo/raw/master/images/202111162152623.png)

## 设计“用户”服务 

### 功能需求：

##### 用户信息管理—CRUD 

### 调用方式：

##### TCP长连接同步交互 

### 协议：

##### 自定义协议

## 接口设计

##### **注册**

```
bool addUser(User user) 
```

##### **更新**

```
bool updateUser(long uid, User user) 
```

#####  **注销**

```
bool deleteUser(long uid) 
```

##### **查询**

```
User Info getUser(long uid)
```

### 序列化协议
远程调用涉及**数据的传输**，就会涉及**组包和解包**，需要调用方和服务方约定数据格式——**序列化协议**
![202111071458027](https://gitee.com/datau001/picgo/raw/master/images/202111162154999.png)
```java
package com.rpcdemo;

import java.io.Serializable;

public class RpcProtocol implements Serializable {

    public static int CMD_CREATE_USER = 1;
    private int version;//=1//创建用户
    private int cmd;//=0//创建用户
    private int magicNum;//=0X20211107//创建用户
    private int bodyLen = 0;//=12//创建用户
    private byte[] body;
    final public static int HEAD_LEN = 16;
}
```
![202111071526146](https://gitee.com/datau001/picgo/raw/master/images/202111162157083.png)

- 以上操作都是在内网,不存在安全问题;外网请求没有魔术这个(`magicNum`)

![202111071523900](https://gitee.com/datau001/picgo/raw/master/images/202111162157885.png)



### `Consumer`代码实现


##### 创建代理类
##### 构造请求数据
##### 执行远程调用

```java
public class RpcClient {
    public static void main(String[] args) {
        //对应的实现在远端，server服务
        UserService proxyUserService = new UserService();

        //构造请求数据
        User user = new User();
        user.setAge((short)26);
        user.setSex((short)1);

        //像调用本地方法一样调用远端服务
        int ret = proxyUserService.addUser(user);
        if(ret == 0){
            System.out.println("调用远程服务创建用户成功！！！");
        }else {
            System.out.println("调用远程服务创建用户失败！！！");
        }
    }
}
```

#### `addUser`
##### 初始化连接
##### 组装协议数据
##### 序列化数据
##### 发送请求等待返回
##### 反序列化返回数据
```java
    public int addUser(User userinfo) {
        /**
         * 初始化连接
         */
        //初始化客户端连接；初步简单写在这里
        TcpClient client = TcpClient.GetInstance();
        try {
            client.init();
        }catch (Exception e){
            e.printStackTrace();
            logger.error("init rpc client error");
        }
        /**
         * 组装协议数据
         */
        //构造请求数据
        RpcProtocol rpcReq = new RpcProtocol();
        rpcReq.setCmd(RpcProtocol.CMD_CREATE_USER);//做一个创建create user的命令行
        rpcReq.setVersion(0x01); //协议用的1.0
        rpcReq.setMagicNum(0x20211107); //
        byte[] body = rpcReq.userInfoTobyteArray(userinfo);//body消息体
        rpcReq.setBodyLen(body.length);
        rpcReq.setBody(body);//对象不能传输，传输的是字节流

        /**
         * 序列化数据
         */
        //第二次序列化把对象变为字节流
        //序列化
        byte[] reqData = rpcReq.gemerateByteArray();
        
        /**
         * 发送请求等待返回
         */
        //发送请求
        client.sendData(reqData);
        //接收请求结果
        byte[] recvData = client.recvData();
        
        //反序列化结果
        RpcProtocol rpcRespHeader = new RpcProtocol();
        rpcRespHeader.byteArrayToRpcHeader(recvData);
        int ret = ByteConverter.bytesToIntBigEndian(rpcRespHeader.getBody(),0);
        return ret;
    }
```

2次代码序列化,一次是传递数据对象的序列化,一次是整体数据(header+body)的序列化



### `RpcProtocol`

**序列化**和**反序列化** : 最终都是对基本数据类型的操作

#### **基本数据类型序列化**

44332211

```java
    public static byte[] intToBytes(int n){
        byte[] buf = new byte[4];
        for (int i = 0; i < buf.length; i++) {
            buf[i] = (byte) (n >> (8 * i));
            
        }
        return buf;
    }
```

#### **基本数据类型反序列化**

11223344

```java
public static int bytesToInt(byte[] buf, int offset){
    return buf[offset] & 0xff //第一个可以说是多余的
            | ((buf[offset + 1] << 8) & 0xff00)
            | ((buf[offset + 2] << 16) & 0xff0000)
            | ((buf[offset + 3] << 24) & 0xff000000);
}
```

#### 序列化过程

##### 序列化请求参数到body

##### 序列化RpcProtocol


序列化请求参数,第一个序列化uid,对应偏移量是Long.BYTES;第二个序列化的是age,对应偏移量Short.BYTES;第三个序列化的是sex,对应偏移量是Short.BYTES
```java
public byte[] userInfoTobyteArray(User userinfo) {
    byte[] data = new byte[Long.BYTES + Short.BYTES + Short.BYTES]
    int index = 0;
    System.arraycopy(ByteConverter.longToBytes(userinfo.getUid()),0,data,index,Long.BYTES);
    index += Long.BYTES;
    System.arraycopy(ByteConverter.shortToBytes(userinfo.getAge()),0,data,index,Short.BYTES);
    index += Short.BYTES;
    System.arraycopy(ByteConverter.shortToBytes(userinfo.getSex()),0,data,index,Short.BYTES);
    return data;
}
```

body序列化完成后,再进行header的序列化

```java
public byte[] generateByteArray() {
    byte[] data = new byte[Long.BYTES + Short.BYTES + Short.BYTES]
    int index = 0;
    System.arraycopy(ByteConverter.intToBytes(version),0,data,index,Integer.BYTES);
    index += Integer.BYTES;
    System.arraycopy(ByteConverter.intToBytes(cmd),0,data,index,Integer.BYTES);
    index += Integer.BYTES;
    System.arraycopy(ByteConverter.intToBytes(magicNum),0,data,index,Integer.BYTES);
    index += Integer.BYTES;
    System.arraycopy(ByteConverter.intToBytes(bodyLen),0,data,index,Integer.BYTES);
    index += Integer.BYTES;
    System.arraycopy(body,0,data,index,body.length);
    return data;
}
```



#### 反序列化过程

##### 反序列化RpcProtocol

##### 反序列化body



![截屏2021-11-17 上午11.35.41](https://gitee.com/datau001/picgo/raw/master/images/202111171136453.png)





![截屏2021-11-17 上午11.35.55](https://gitee.com/datau001/picgo/raw/master/images/202111171136504.png)

![截屏2021-11-17 上午11.44.33](https://gitee.com/datau001/picgo/raw/master/images/202111171144172.png)





### `Provider`代码实现{服务端}

![202111111655307](https://gitee.com/datau001/picgo/raw/master/images/202111162159494.png)


#### 启动服务监听端口

**定长header**,随时可**变长的body**

![截屏2021-11-17 上午11.52.50](https://gitee.com/datau001/picgo/raw/master/images/202111171153983.png)

##### Server启动

![截屏2021-11-17 下午2.37.13](https://gitee.com/datau001/picgo/raw/master/images/202111171437583.png)

#### 请求包完整性校验

##### 判断包头是否完整

- 包头是固定的，定长的

##### 判断body是否完整

![截屏2021-11-17 下午2.38.14](https://gitee.com/datau001/picgo/raw/master/images/202111171438408.png)

#### 请求处理
##### 反序列化
##### 包校验
##### 请求分发
##### 返回结果构造



![截屏2021-11-17 下午2.42.31](https://gitee.com/datau001/picgo/raw/master/images/202111171442424.png)

###### body部分的序列化

![截屏2021-11-17 下午2.42.55](https://gitee.com/datau001/picgo/raw/master/images/202111171443203.png)

###### 数据整体反序列化

![截屏2021-11-17 下午2.44.54](https://gitee.com/datau001/picgo/raw/master/images/202111171445643.png)

# 03」RPC服务消费方核心功能设计实现

RPC产品是什么样

仅仅实现远程调用是不够的，离产品化还有很长一段时间

- **数据传输**

- **序列化/反序列化**

- **客户端代理类实现**

- **请求映射分发**

**仅此而已？作为RPC产品还需要哪些功能**

### Consumer

##### 连接管理
- 直接创建了，没有对应管理
##### 负载均衡
- 以上代码也没涉及到负载

##### 请求路由

```
A 发送请求到 B B' B'' B'''
通过路由让A发送的数据分别到以上4个节点
期望某些具体的流量只请求 B B' 
另外一些请求只发送到 B'' B'''
根据一些规则进行路由的分发
```

##### 超时处理
```
A 发送到B上的请求，超过10s没有反应
就直接去请求另外节点
```

##### 健康检查
```
有4个节点，没准哪个不干活了，我要知道，并且把该节点摘除掉
```
#### Provider「服务提供方」

##### 队列/线程池

- 涉及资源隔离

##### 超时丢弃

- 队列里面的内容，超时了之后，就丢弃了

##### 优雅关闭

- B重启，A发送给B，一重启就丢请求
- 优雅关闭：重启也不丢流量和请求

##### 过载保护

- 请求太多的时候，服务器会被压死；这个时候，返回错误，异常

## Consumer功能分析

- 连接管理

- 负载均衡

- 请求路由

- 超时处理

![未命名文件](https://gitee.com/datau001/picgo/raw/master/images/202111172031225.png)

- **ProviderA-***都是用户服务
- **Business logic**通过代理去做远程调用，代理方法去调用序列化，序列化以后通过管理模块「Connect manage」去发送请求，选择一个`ProviderA-*`发出去，选择的过程我们叫**负载均衡**
- 数据回来以后，我们做反序列化，返回

以上是连接的模块

### 01）连接管理

保持与服务提供方长连接，用于传输请求数据也返回结果

#### 初始化时机

- 模块启动了，什么时候和调用的模块建立连接，就是初始化时机

- 不一定先建好连接时机就好，如果开始就创建好连接，会有很多无效连接
- 解决：懒加载；请求来了，网关层「GW」开始慢慢预热并初始化创建连接
- 需要一小部分流量先打过来，然后再GW网关层分发连接，慢慢建立起来；如果一次性流量很大，则上游会报TimeOut错误
- 下游连接A的时候，由于A服务又调用B,C两个服务，对应调用数量不多，则在初始化A的时候就可以进行BC的初始化；

![截屏2021-11-17 下午9.12.31](https://gitee.com/datau001/picgo/raw/master/images/202111172112794.png)

#### 连接数维护

- A调用B，只见一条连接，如果连接断了？？？则还需要重新创建；
- A与B创建连接的时候，不只是创建一条连接，要创建一个连接池，这样哪怕其中一条连接断了，也不影响

- 心跳/重连
  - 进行连接的监听，如果断开连接，则准备重新连接

- 客户端线程模型
    - 客户端代码和DB数据库连接，就是**同步**的，创建了这个连接，就不会被其他的线程读取到，是**独占**式的
      - 独占式的锁链接方式有一个现象：**与数据库连接的池，pool(10)有10个连接，当一条链接一条线程使用，10个连接都占用了以后，报错：没有可用连接了**
      
    - double服务不是独占式的，所以敢说创建一个连接就可以

      

![截屏2021-11-17 下午9.49.06](https://gitee.com/datau001/picgo/raw/master/images/202111172150059.png)

![截屏2021-11-17 下午10.19.52](https://gitee.com/datau001/picgo/raw/master/images/202111172220159.png)



- 创建连接一个就够，对应数据传送是I/O连接
- 但是我的业务getUser是需要读取数据的，这个时候我创建的RPC服务就需要阻塞住了
  - 发出去的数据包 和 回来的数据包 要**配对**「怎么配对」
  - 工作线程阻塞着，数据回来了以后，需要对工作线程进行**唤醒**「怎么唤醒」

### 02）负载均衡

确保多个服务提供方节点流量合理，支持节点扩容与灰度发布 

![截屏2021-11-17 下午10.48.45](https://gitee.com/datau001/picgo/raw/master/images/202111172249560.png)


- 业务模块，把远程调用交给proxy代理,然后开始数据进行序列化，后面LB，加了一层负载均衡。选择出哪个节点来，进行连接管理，数据传输，数据返回过来再进行一个反序列化

有以下几种：

#### 轮询

![截屏2021-11-17 下午11.11.01](https://gitee.com/datau001/picgo/raw/master/images/202111172311632.png)

#### 随机

#### 取模

- 类似分库分表
- 有状态的服务才进行取模

- 比如redis存储数据量过多，我们可以放2个redis进行存储，对应的uid除以2，这样每个redis都是存取 50%

![截屏2021-11-17 下午11.16.52](https://gitee.com/datau001/picgo/raw/master/images/202111172317663.png)

#### 带权重「重点讲」

- 根据权重去分散对应流量

#### 一致性Hash
**带故障转移的负载均衡**
- 最小值到最大值是一个环形
- 最后请求都压到一个节点上，可能会导致 雪崩

负载均衡不一定就是请求/流量分布均匀，我们可以根据业务进行对应的调控，以达到我们的预期

### 02.1）权重负载均衡设计

##### 权重0～10范围内取值

##### 值越大表示权重越高

##### 权重高分配流量比例大

![截屏2021-11-17 下午11.28.39](https://gitee.com/datau001/picgo/raw/master/images/202111172329064.png)



#### 数据结构

- 数组，根据权重值填充
- **0，1的位置随机打乱**

|1|0|0|1|0|1|0|1|
|---|---|---|---|---|---|---|---|

#### 算法描述

- 负载均衡选出一个结点
- 生成0～9之间随机值
- 对应数组中的值
  - 0使用该节点
  - 1不使用该节点

随机数组意义：
如果一个公司一天上万或者上亿个请求，只需要在最开始的时候，**1，0位置随机打乱**，轮询的去访问它，下一个不知道是0还是1，随机的，通过这个随机数组「权重数组」，轮询的去访问达到了随机的效果，等价于生成随机数，但是对应访问量就少很多，只需要最开始的时候进行访问它，生成随机数组就可以了，减少了计算和公司的资源，这不是省去了一次计算，是一次计算省去了n次计算


随机数组意义？来一个流量访问随机数组判断是0还是1，跟访问节点有什么关系？？？
- 老师回答：预先生成随机数，通过空间换取时间。每个节点有一个随机数组，按列轮询每个节点数组，达到随机效果
- 先选节点，然后根据随机数组的0，1配比达到权重判断，就是刚开始大家都是10个权重，到固定节点的时候再结合随机数组进行权重控制


- 负载策略分：轮询、随机、取模、一致性Hash，权重负载是不是随机带权重？？
    - 轮询权重+随机权重
- 每个节点都有自己的权重数组。权重数组随机打乱，达到随机性。避免random的开销
- 如果伦序的负载，已经明确是轮着来了，为什么再加个权重做干预？
    - 轮询是轮询，权重是权重
    - 轮询到A可能会因为A权重的配比放弃，执行下一个轮询

#### 轮询数组初始化
随机数组生成
- num表示1的个数
- 随机填充数组
```java
public static byte[] randomGenerator(int limit, int num){
    byte[] temArray = new byte[limit];
    if(num <= 0){
        ...
    }
    if(num >= limit){
        ...
    }
    //以上为初始化
    //开始循环
    Random random = new Random();
    //随机生成一个下标
    for (int i = 0; i < num; i++) {

        int temp = Math.abs(random.nextInt()) % limit;
        while (temArray[temp] == 1){
            //如果对应的值为1，那么再生成一个随机的
            temp = Math.abs(random.nextInt()) % limit;
        }
        temArray[temp] = 1;
        //直到最后所有的都是1
    }
 }
```
#### 轮询+权重负载均衡实现

- 轮询到某一Server结点
- 根据权重再进行一次过滤
- 轮询到下一个结点

```java
for (int i = start; i < start + count; i++) {
    int index = i % count;
    Server server = servers.get(index)
    if (needChooseAnotherOne.test(server)) {
        requestCount.getAndIncrement();
        continue;
    }

    int requestTime = this.getRequestTimeCountAndSet(server, count);
    if (server.getWeight() < 10 && server.getWeight() > -1){
        byte[] abandonArray = server.getAbandonArray();
        //abandonTimes[i] == 1 表示server不接受该次请求
        if(abandonArray[requestTime % abandonArray.length] == 1){
            continue;
        }
    }
    if(ServerState.Normal == server.getState()){
        result = server;
        break;
    }
    requestCount.getAndIncrement();


}
```

### 03）请求路由

通过一系列规则过滤出可以选择的服务提供方节点列表，在**应用隔离**，**读写隔离**，**灰度发布**中都发挥作用「路由就是一条一条的规则」

![截屏2021-11-20 下午4.48.27](https://gitee.com/datau001/picgo/raw/master/images/202111201648424.png)

#### 路由功能设计实现
##### 规则描述
- 待比较属性
    - 比较的是`ip`还是特定的`标签`
- 运算符
    - `>` `<`  `=` `in`
- 属性匹配值
    - 要匹配谁
- 匹配结点
##### 数据结构设计
- 链表
    - 每条的输出就是下一条的输入，和用filter一样

![截屏2021-11-20 下午4.13.51](https://gitee.com/datau001/picgo/raw/master/images/202111201614202.png)

IP 分流规则举例：
```
attritube=IP,operator=IN,value=IP1,IP2,Servers:Node1,Node2



attritube=IP(待比较的属性是IP)
perator=IN(对应的运算符是in)
value=IP1,IP2(这两个指定的IP)（根据IP找对应node节点，进行一个数据分流）
Servers:Node1,Node2()
```
##### doubble 对应设计

![截屏2021-11-20 下午4.47.37](https://gitee.com/datau001/picgo/raw/master/images/202111201647562.png)


- `Filter1`之前我们可以调用的列表有：`ProviderA-1，2，3，4`
- `Filter1`过滤之后，可以调用服务列表：`ProviderA-2，3，4`
- `Filter2`告诉我们只有灰度流量可以访问`ProviderA-1`

这个时候我们知道，有两种流量：正常流量可以访问`2，3，4`；灰度流量访问`1`
如果反过来会怎样？？？？
反过来场景：
- `filter`后，灰度流量可以访问`ProviderA-1`；正常流量可以访问`ProviderA-1，2，3，4`
- 再次`filter`后，灰度流量没有可调用服务，正常流量可调用`ProviderA-2，3，4`

所以：**`filter`顺序很重要**

### 04）超时处理

对于长时间没有返回的请求，需要作出异常处理，及时释放资源

![截屏2021-11-20 下午4.58.54](https://gitee.com/datau001/picgo/raw/master/images/202111201659253.png)

#### 调用方超时处理
##### 工作线程阻塞位置
- 等待回包通知
##### 超时逻辑
- 工作线程等待通知
- 数据返回终止等待
- 超时抛出异常
##### 数据结构设计
- `map`: `SessionID-WindowData`



##### 代理类请求发送和接收调用逻辑

- 1、注册WindowData
    - `sessionID`:A 发送请求给 B，会带着一个唯一的session ID，等B返回请求的时候，A识别到session ID就知道这个请求是我当初发送的
    - 等回包的时候根据session ID进行匹配
    - WindowData是我们请求需要的数据
- 2、异步发送

- 3、等待数据到达

- 4、注销WindowData

```java
public Protocol request(Protocol requestProtocol) throws Exception {
        //Server状态判断
        if (ServerState.Reboot == state || ServerState.Dead == state) {
            throw new RebootException();
        }
        increaseCU();
        CSocket socket = null;
        try {
            try {
                socket = socketPool.getSocket();
                //要发送的数据进行序列化
                byte[] data = requestProtocol.toBytes(socket.isRights(), socket.getDESKey());
                //注册WindowData，放入SessionID-WindowData的Map
                socket.registerRec(requestProtocol.getSessionID());
                //异步发送，将数据放入发送队列
                socket.send(data);
            } catch (TimeoutException e) { 
                timeout();
                throw e;
            } catch (IOException e) {
                if (socket == null || !socket.connecting()) {
                    if (testServerState() != ServerState.Normal) {
                        this.asDeath();
                        logger.info("this server : {}  is dead , will choose another one !", address);
//                        logger.error(String.format("server %s is dead", new Object[]{this.address}), e);
                        throw new RebootException();
                    }
                }
                throw e;
            } catch (Exception e) {
                throw e;
            } finally {
                if (socket != null) {
                    socket.dispose();
                }
            }
            
            //接收数据（等待数据到达通知）
            byte[] buffer = socket.receive(requestProtocol.getSessionID(), currUserCount);
            Protocol receiveProtocol = Protocol.fromBytes(buffer, socket.isRights(), socket.getDESKey());
			
            return receiveProtocol;
        } finally {
            if (socket != null) {
                //注销WindowData
                socket.unregisterRec(requestProtocol.getSessionID());
            }
        }
```

- registerRec里面注册了一个事件`AutoResetEvent event = new AutoResetEvent();`
- `WindowData wd = new WindowData(event);`用一个事件来构造它
- 对应请求放在队列里面
- run()去发送，从待发送队列里面做了一个5个的时候进行发送；聚合5个一起发送，提高IO效率，别有一个发一个
- 一个是5个task上限；一个是时间time上限；先到哪个就先发哪个

**回包（重点）**

- 先根据sessessionID把widowData取出来，如果windowData没有
# RPC服务提供方核心功能设计实现

## Provider功能分析
### 队列/线程池
将不同类型的请求，放入各自的队列，每个队列分配独立的线程池，资源隔离

![截屏2021-11-20 下午5.33.36](https://gitee.com/datau001/picgo/raw/master/images/202111201733880.png)
- consumer1调用都在第一个thread pool里面，consumer1 不可用了，全部都卡死了，但是2，3，4还是可以


**队列数，线程池线程数如何选择？**
##### 线程池分配 
- 单队列多线程 `1*64`
    - 1个队列有64条线程消费
    - 对应锁竞争比较大，缺点：**lock开销大**
    - 优点：**慢请求**的适应能力强
- 多队列单线程 `64*1`
    - 一条队列配置一个线程
    - 优点：不用➕锁
    - 缺点：慢请求适应能力很差

还有一种m*n，以下实验验证：
慢请求，锁开销就是性能

![截屏2021-11-20 下午5.39.46](https://gitee.com/datau001/picgo/raw/master/images/202111201740219.png)

IO线程收到请求入队列；T1时刻请求入队列，T2时刻请求出队列；然后进入工作线程处理；T3时刻工作线程处理完

- `64*1`
    - QPS 压到2万，5万，10万的时候
    - 排队时间：`（T2 - T1）`
     请求的处理时间：`（T3 - T2）`
      执行时间：`（T3 - T1）`

![截屏2021-11-20 下午6.14.24](https://gitee.com/datau001/picgo/raw/master/images/202111201814720.png)

第一节课考试🔗：

https://apprz8zztzy8571.h5.xiaoeknow.com/evaluation_wechat/examination/review/ex_6182791dbaffb_AqgrN9r6/uexam_6198cbe206f65_Qz53M876gd?content_app_id=



### 超时丢弃

### 优雅关闭
### 过载保护